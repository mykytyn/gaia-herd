{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-N_LWQheTU9"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astroquery.vizier import Vizier\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy as ap\n",
    "import george\n",
    "from george import kernels\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import sklearn\n",
    "from sklearn.neighbors import KernelDensity as KD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrGNZNGFc10n"
   },
   "outputs": [],
   "source": [
    "Vizier = Vizier(row_limit=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thUK1NUldxdp"
   },
   "outputs": [],
   "source": [
    "catalog = Vizier.get_catalogs(\"J/A+A/618/A93\")\n",
    "\n",
    "clucata = catalog[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QOpNlLlDhGPI"
   },
   "outputs": [],
   "source": [
    "newc = clucata.group_by('Cluster')\n",
    "\n",
    "maxcluster = np.argmax(newc.groups.indices[1:]-newc.groups.indices[:-1])\n",
    "bigcluster = newc.groups[maxcluster+6]\n",
    "print(bigcluster.colnames)\n",
    "newc.groups[maxcluster+6]['Cluster'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good `'Cluster'`s to choose from: Alessi\\_24, ASCC_99, Alessi\\_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutcluster = bigcluster[bigcluster['PMemb']>.8]\n",
    "cutcluster = cutcluster[~np.isnan(cutcluster[\"BP-RP\"])]\n",
    "#We should cut by lines away from main sequence\n",
    "cutcluster = cutcluster[~np.logical_and(cutcluster[\"BP-RP\"]>1.0,cutcluster[\"Gmag\"]<10.)]\n",
    "cutcluster = cutcluster[~np.logical_and(cutcluster[\"BP-RP\"]<.7, cutcluster[\"Gmag\"]>13.8)]\n",
    "plt.plot(cutcluster['RA_ICRS'],cutcluster['DE_ICRS'],'+')\n",
    "plt.title('angular coordinates of '+cutcluster['Cluster'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cutcluster['PMemb'])\n",
    "plt.xlabel('PMemb')\n",
    "plt.title('cluster membership probability of '+cutcluster['Cluster'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cutcluster['BP-RP'],cutcluster['Gmag'], '+')\n",
    "plt.ylim(19, 7)\n",
    "plt.xlabel('BP-RP')\n",
    "plt.ylabel('Gmag')\n",
    "plt.title('color-magnitude diagram of '+cutcluster['Cluster'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA - diagram, inverse of variance as metric -> sqrt(thing)= transformation, apply ->PCA(test) -> KDE -> inverse transform both L and R on Kernel Widths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLE? -> Local linear embedding -> for non MS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove outliers before PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(np.vstack((cutcluster['BP-RP'], cutcluster['Gmag']))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n",
    "cmd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_pca.transform(X)[:,0],X_pca.transform(X)[:,1],'+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X1, X2 = np.meshgrid(np.linspace(0, 3, 50), np.linspace(18, 7, 50))\n",
    "X_grid = np.array([np.ravel(X1), np.ravel(X2)]).T\n",
    "X_transform = pca.transform(X)\n",
    "Z_grid = pca.transform(X_grid)[:, 0].reshape(X1.shape)\n",
    "plt.contour(X1, X2, Z_grid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = pca.transform(X)\n",
    "X_transform.shape\n",
    "plt.scatter(X_transform[:,0], X_transform[:,1])\n",
    "plt.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "\n",
    "# plot data\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "    v = vector * 3 * np.sqrt(length)\n",
    "    draw_vector(pca.mean_, pca.mean_ + v)\n",
    "plt.axis('equal');\n",
    "plt.ylim(18,7)\n",
    "plt.xlim(-2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(X)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "plt.axis('equal')\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I couldn't immediately find a KDE code that enabled different bandwidth in each dimension\n",
    "# which we want because the errors in color are much greater than the errors in magnitude\n",
    "params = {'bandwidth': np.logspace(-2, 0, 200)}\n",
    "grid = GridSearchCV(KD(kernel='linear'), params, cv=5)\n",
    "grid.fit(X_pca)\n",
    "\n",
    "print(\"best bandwidth: {0}\".format(grid.best_estimator_.bandwidth))\n",
    "# first attempt obviously too fine a bandwidth because it allows for double stars\n",
    "# we could fix it here or say this is just what the data is and fit an HRD model that doesn't permit those\n",
    "# so now the data is the KDE evaluated on a grid\n",
    "\n",
    "kde = grid.best_estimator_.fit(X_pca)\n",
    "eval_where = np.array(list(product(np.linspace(-4,6,50), np.linspace(-1,1, 50))))\n",
    "log_dens = kde.score_samples(eval_where)\n",
    "\n",
    "plt.imshow(np.flip(np.exp(log_dens.reshape(50, 50).T), axis=0),extent=[-4, 6, -1, 1])\n",
    "#plt.scatter(cutcluster['BP-RP'], cutcluster['Gmag'], marker='.', color='r', s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_pca[:,1], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.ones(3)\n",
    "with pm.Model() as model:\n",
    "    w = pm.Dirichlet('w', np.ones_like(W))\n",
    "\n",
    "    mu1 = pm.Normal('mu1', -.09, .1)\n",
    "    mu2 = pm.Normal('mu2', 0.19, .05)\n",
    "    mu3 = pm.Normal('mu3', .4, .1)\n",
    "    \n",
    "    mu = [mu1, mu2, mu3]\n",
    "    tau = pm.Gamma('tau', alpha=1, beta=1, shape=W.size)\n",
    "\n",
    "\n",
    "    #p_min_potential = pm.Potential('p_min_potential', tt.switch(tt.min(w) < .1, -np.inf, 0))\n",
    "    # break symmetry\n",
    "    #order_means_potential = pm.Potential('order_means_potential',\n",
    "     #                                    tt.switch(mu[1]-mu[0] < 0, -np.inf, 0)\n",
    "      #                                   + tt.switch(mu[2]-mu[1] < 0, -np.inf, 0))\n",
    "\n",
    "\n",
    "    x_obs = pm.NormalMixture('x_obs', w, mu, tau=tau, observed=X_pca[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(50000, n_init=1000, tune=1000, chains=2)[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, varnames=['w', 'mu1', 'mu2','mu3','tau']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    ppc_trace = pm.sample_posterior_predictive(trace, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newthing = ppc_trace['x_obs'][np.logical_and(ppc_trace['x_obs'][:,0]>-1, ppc_trace['x_obs'][:,0]<1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newthing[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_pca[:,1], bins=20, lw=2, histtype='step', density=True)\n",
    "plt.hist(newthing[:,0], bins=20, density=True,\n",
    "        histtype='step', lw=2,\n",
    "        label='Posterior predictive distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for varname in trace.varnames:\n",
    "    print(varname, trace[varname].mean(axis=0),np.var(trace[varname],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.inverse_transform([[-4,-1],[-4,1],[6,-1],[6,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pca.inverse_transform(X_pca)\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], color='g', alpha=0.4)\n",
    "plt.imshow(np.flip(np.exp(log_dens.reshape(50, 50).T), axis=0),extent=[])\n",
    "plt.ylim(18,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(X_transform);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_back[:, 0], X_back[:, 1], c=\"red\",\n",
    "            s=20, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = np.asarray(np.vstack((cutcluster['BP-RP'], cutcluster['Gmag']))).T\n",
    "print((np.min(cutcluster['BP-RP']), np.max(cutcluster['BP-RP']), np.min(cutcluster['Gmag']), np.max(cutcluster['Gmag'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I couldn't immediately find a KDE code that enabled different bandwidth in each dimension\n",
    "# which we want because the errors in color are much greater than the errors in magnitude\n",
    "params = {'bandwidth': np.logspace(-5, -2, 200)}\n",
    "grid = GridSearchCV(KD(kernel='exponential'), params, cv=5)\n",
    "grid.fit(X_pca)\n",
    "\n",
    "print(\"best bandwidth: {0}\".format(grid.best_estimator_.bandwidth))\n",
    "# first attempt obviously too fine a bandwidth because it allows for double stars\n",
    "# we could fix it here or say this is just what the data is and fit an HRD model that doesn't permit those\n",
    "# so now the data is the KDE evaluated on a grid\n",
    "\n",
    "kde = grid.best_estimator_.fit(cmd)\n",
    "eval_where = np.array(list(product(np.linspace(0., 2.7, 50), np.linspace(18., 7., 50))))\n",
    "log_dens = kde.score_samples(eval_where)\n",
    "\n",
    "plt.imshow(np.flip(np.exp(log_dens.reshape(50, 50).T), axis=0), extent=[0., 2.7, 18., 7.], aspect=0.25)\n",
    "#plt.scatter(cutcluster['BP-RP'], cutcluster['Gmag'], marker='.', color='r', s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = eval_where\n",
    "y = log_dens\n",
    "y.shape\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 5*kernels.Matern52Kernel(5., ndim=2)\n",
    "gp = george.GP(kernel, mean=np.mean(y), fit_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.compute(x)\n",
    "\n",
    "test_x = np.array(list(product(np.linspace(0, 3, 100),np.linspace(7,18,100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, pred_var = gp.predict(y, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.exp(pred.reshape(100, 100).T), extent=[0., 3, 18., 7.], aspect=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as op\n",
    "\n",
    "# Define the objective function (negative log-likelihood in this case).\n",
    "def nll(p):\n",
    "    gp.set_parameter_vector(p)\n",
    "    ll = gp.log_likelihood(y, quiet=True)\n",
    "    return -ll if np.isfinite(ll) else 1e25\n",
    "\n",
    "# And the gradient of the objective function.\n",
    "def grad_nll(p):\n",
    "    gp.set_parameter_vector(p)\n",
    "    return -gp.grad_log_likelihood(y, quiet=True)\n",
    "\n",
    "# You need to compute the GP once before starting the optimization.\n",
    "gp.compute(x)\n",
    "\n",
    "# Print the initial ln-likelihood.\n",
    "print(gp.log_likelihood(y))\n",
    "\n",
    "# Run the optimization routine.\n",
    "p0 = gp.get_parameter_vector()\n",
    "results = op.minimize(nll, p0, jac=grad_nll, method=\"L-BFGS-B\")\n",
    "\n",
    "# Update the kernel and print the final log-likelihood.\n",
    "gp.set_parameter_vector(results.x)\n",
    "print(gp.log_likelihood(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, pred_var = gp.predict(y, test_x)\n",
    "\n",
    "\n",
    "plt.scatter(cutcluster['BP-RP'], cutcluster['Gmag'], marker='.', color='r', s=1)\n",
    "plt.imshow(np.exp(pred.reshape(100, 100).T), extent=[0., 3, 18., 7.], aspect=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "test-realtime",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
